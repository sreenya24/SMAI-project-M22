{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BOW():\n",
    "    def __init__(self, k_val, b_val):\n",
    "        # Constants\n",
    "        self.k_val = k_val\n",
    "        self.b_val = b_val\n",
    "\n",
    "        # Vocabulary contains the words in the corpus and the number of documents they appear in\n",
    "        self.vocabulary = {}\n",
    "        self.vocabulary_arr = None\n",
    "        self.vocab_size = None\n",
    "        \n",
    "        # Documents contains the words in each document and the number of times they appear\n",
    "        self.documents = {}\n",
    "        self.document_vectors = None\n",
    "        self.doc_count = None\n",
    "        self.max_docs = None\n",
    "        self.avg_doc_length = None\n",
    "\n",
    "        # score matrices\n",
    "        self.tf_matrix = None\n",
    "        self.idf_matrix = None\n",
    "    \n",
    "    def create(self, path_to_annotations):\n",
    "\n",
    "        self.doc_count = 0\n",
    "        for (root, dirs, files) in os.walk(path_to_annotations, topdown=True):\n",
    "            print(root)\n",
    "            # print(dirs)\n",
    "            # print(files)\n",
    "            for file in files:\n",
    "                file_num = file.split('.')[0]\n",
    "                file_num = int(file_num)\n",
    "                # parses the annotation file and adds the words to the vocabulary\n",
    "                self.parse_annotation_file(os.path.join(root, file), file_num)\n",
    "                self.doc_count += 1\n",
    "\n",
    "        self.vocab_size = len(self.vocabulary)\n",
    "\n",
    "        self.vocabulary_arr = np.array(list(self.vocabulary))\n",
    "\n",
    "        # make document vectors\n",
    "        self.max_docs = max(self.documents.keys())+1\n",
    "        self.document_vectors = np.zeros((self.max_docs, self.vocab_size))\n",
    "        \n",
    "        for doc_num in self.documents.keys():\n",
    "            for word in self.documents[doc_num]:\n",
    "                word_index = np.where(self.vocabulary_arr == word)[0][0]\n",
    "                self.document_vectors[doc_num][word_index] = self.documents[doc_num][word]\n",
    "\n",
    "        self.avg_doc_length = np.sum(self.document_vectors) / self.doc_count\n",
    "\n",
    "    def form_matrix(self):\n",
    "        if(self.vocabulary_arr is None):\n",
    "            print(\"vocabulary is none\")\n",
    "            print(\"run create() first\")\n",
    "\n",
    "        # calculate idf\n",
    "        values = self.vocabulary.values()\n",
    "        values = np.array(list(values))\n",
    "        self.idf_matrix = np.log((self.doc_count + 1) / (values + 0.5))\n",
    "\n",
    "        # calculate tf\n",
    "        self.tf_matrix = self.k_val*self.document_vectors / (self.k_val * (1 - self.b_val + (self.b_val * (np.sum(self.document_vectors,axis=1).T/ self.avg_doc_length))) + self.document_vectors.T).T   \n",
    "\n",
    "        return self.tf_matrix, self.idf_matrix  \n",
    "\n",
    "    def get_query_score(self, query_num, doc_num):\n",
    "        if(self.idf_matrix is None):\n",
    "            print(\"idf matrix is none\")\n",
    "            print(\"run form_matrix() first\")\n",
    "        if(self.tf_matrix is None):\n",
    "            print(\"tf matrix is none\")\n",
    "            print(\"run form_matrix() first\")\n",
    "\n",
    "        # vector = self.get_query_vector(path_to_query)\n",
    "        # tf_q = self.get_query_tf(vector)\n",
    "        tf_q = self.tf_matrix[query_num]\n",
    "        tf_d = self.tf_matrix[doc_num]\n",
    "        idf = self.idf_matrix\n",
    "        return np.sum(tf_q*tf_d*idf*idf)\n",
    "\n",
    "    def get_query_tf(self, query_vector):\n",
    "        return self.k_val*query_vector / (self.k_val * (1 - self.b_val + self.b_val * (np.sum(query_vector).T/ self.avg_doc_length)) + query_vector.T).T\n",
    "\n",
    "    def get_query_vector(self, path_to_query):\n",
    "        query_tf_vector = np.zeros(self.vocab_size)\n",
    "        with open(path_to_query, 'r', encoding='latin-1') as f:\n",
    "            # read the doc as a string\n",
    "            doc = f.read()\n",
    "            \n",
    "            # get the words in the doc\n",
    "            words_in_doc = self.get_words_in_doc(doc)\n",
    "\n",
    "            for word in words_in_doc:\n",
    "                word_index = np.where(self.vocabulary_arr == word)[0][0]\n",
    "                query_tf_vector[word_index] = words_in_doc[word]\n",
    "            \n",
    "        return query_tf_vector\n",
    "\n",
    "    def parse_annotation_file(self, path_to_annotation_file, file_number):\n",
    "        # open in latin-1 encoding to avoid UnicodeDecodeError\n",
    "        with open(path_to_annotation_file, 'r', encoding='latin-1') as f:\n",
    "            # read the doc as a string\n",
    "            doc = f.read()\n",
    "            \n",
    "            # get the words in the doc\n",
    "            words_in_doc = self.get_words_in_doc(doc)\n",
    "            \n",
    "            # add the words in the document to the vocabulary\n",
    "            self.documents[file_number] = words_in_doc\n",
    "\n",
    "            for word in words_in_doc:\n",
    "                if word in self.vocabulary:\n",
    "                    self.vocabulary[word] += 1\n",
    "                else:\n",
    "                    self.vocabulary[word] = 1\n",
    "\n",
    "    def get_words_in_doc(self, doc):\n",
    "\n",
    "        # replace \\n with space\n",
    "        doc = doc.replace('\\n', ' ')\n",
    "        # get parts between all <TITLE> and </TITLE> tags\n",
    "        titles = re.findall(r'<TITLE>(.*?)</TITLE>', doc)\n",
    "        # get parts between all <DESCRIPTION> and </DESCRIPTION> tags\n",
    "        descriptions = re.findall(r'<DESCRIPTION>(.*?)</DESCRIPTION>', doc)\n",
    "        # get parts between all <NOTES> and </NOTES> tags\n",
    "        notes = re.findall(r'<NOTES>(.*?)</NOTES>', doc)\n",
    "        # get parts between all <LOCATION> and </LOCATION> tags\n",
    "        locations = re.findall(r'<LOCATION>(.*?)</LOCATION>', doc)\n",
    "\n",
    "        words_in_doc = {}\n",
    "\n",
    "        # split into words and add to vocabulary\n",
    "        for title in titles:\n",
    "            for word in title.split():\n",
    "                word = word.strip(' .,;:!?()[]\\{\\}\\'\\\"')\n",
    "                word = word.lower()\n",
    "                if word not in words_in_doc:\n",
    "                    words_in_doc[word] = 0\n",
    "                words_in_doc[word] += 1\n",
    "\n",
    "        for description in descriptions:\n",
    "            for word in description.split():\n",
    "                word = word.strip('.,;:!?()[]\\{\\}\\'\\\"')\n",
    "                word = word.lower()\n",
    "                if word not in words_in_doc:\n",
    "                    words_in_doc[word] = 0\n",
    "                words_in_doc[word] += 1\n",
    "\n",
    "        for note in notes:\n",
    "            for word in note.split():\n",
    "                word = word.strip('.,;:!?()[]\\{\\}\\'\\\"')\n",
    "                word = word.lower()\n",
    "                if word not in words_in_doc:\n",
    "                    words_in_doc[word] = 0\n",
    "                words_in_doc[word] += 1\n",
    "\n",
    "        for location in locations:\n",
    "            for word in location.split():\n",
    "                word = word.strip('.,;:!?()[]\\{\\}\\'\\\"')\n",
    "                word = word.lower()\n",
    "                if word not in words_in_doc:\n",
    "                    words_in_doc[word] = 0\n",
    "                words_in_doc[word] += 1\n",
    "\n",
    "        return words_in_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Smol_set/annotations_complete_eng/\n",
      "./Smol_set/annotations_complete_eng/00\n",
      "./Smol_set/annotations_complete_eng/01\n",
      "./Smol_set/annotations_complete_eng/02\n",
      "./Smol_set/annotations_complete_eng/03\n",
      "./Smol_set/annotations_complete_eng/04\n",
      "./Smol_set/annotations_complete_eng/05\n"
     ]
    }
   ],
   "source": [
    "path_to_annotations = './Smol_set/annotations_complete_eng/'\n",
    "k_val = 1.5\n",
    "b_val = 0.75\n",
    "bow = BOW(k_val, b_val)\n",
    "bow.create(path_to_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_matrix, idf_matrix = bow.form_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.9214412247644646\n"
     ]
    }
   ],
   "source": [
    "sample = bow.get_query_score(2095,4323)\n",
    "\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "file 1\n",
      "<DOC>\n",
      "<DOCNO>annotations/04/4323.eng</DOCNO>\n",
      "<TITLE>Photo of the host family Schuler</TITLE>\n",
      "<DESCRIPTION>two men and a woman are sitting at a table and a dog is sitting next to it; there are flower pots and a black book on the table, and white flowers and a wall behind it;</DESCRIPTION>\n",
      "<NOTES></NOTES>\n",
      "<LOCATION>Buenos Aires, Argentina</LOCATION>\n",
      "<DATE>May 2002</DATE>\n",
      "<IMAGE>images/04/4323.jpg</IMAGE>\n",
      "<THUMBNAIL>thumbnails/04/4323.jpg</THUMBNAIL>\n",
      "</DOC>\n",
      "-------------------------------\n",
      "file 2\n",
      "<DOC>\n",
      "<DOCNO>annotations/02/2095.eng</DOCNO>\n",
      "<TITLE>The train from Cusco to Puno in the Altiplano</TITLE>\n",
      "<DESCRIPTION>an orange and yellow train on a pass; there are snow covered mountains on the left and in the background, and some tourists stretching their legs on the right;</DESCRIPTION>\n",
      "<NOTES>The train from Cuzco to Puno stops at the La Raya Pass; </NOTES>\n",
      "<LOCATION>Cuzco, Peru</LOCATION>\n",
      "<DATE>August 2002</DATE>\n",
      "<IMAGE>images/02/2095.jpg</IMAGE>\n",
      "<THUMBNAIL>thumbnails/02/2095.jpg</THUMBNAIL>\n",
      "</DOC>\n",
      "-------------------------------\n",
      "score:  4.9214412247644646\n"
     ]
    }
   ],
   "source": [
    "file_1 = 4323\n",
    "file_2 = 2095\n",
    "\n",
    "out = bow.get_query_score(file_1,file_2)\n",
    "\n",
    "path_1 = f'./Smol_set/annotations_complete_eng/0{str(file_1)[0]}/{file_1}.eng'\n",
    "path_2 = f'./Smol_set/annotations_complete_eng/0{str(file_2)[0]}/{file_2}.eng'\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"file 1\")\n",
    "with open(path_1, 'r', encoding='latin-1') as f:\n",
    "    doc_1 = f.read()\n",
    "    print(doc_1)\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"file 2\")\n",
    "with open(path_2, 'r', encoding='latin-1') as f:\n",
    "    doc_2 = f.read()\n",
    "    print(doc_2)\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"score: \", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "file 1\n",
      "<DOC>\n",
      "<DOCNO>annotations/03/3191.eng</DOCNO>\n",
      "<TITLE>Anaconda</TITLE>\n",
      "<DESCRIPTION>an anaconda on a tree trunk in an aquarium;</DESCRIPTION>\n",
      "<NOTES>Scientific name: Eunectes</NOTES>\n",
      "<LOCATION>São Paulo, Brazil</LOCATION>\n",
      "<DATE>February 2002</DATE>\n",
      "<IMAGE>images/03/3191.jpg</IMAGE>\n",
      "<THUMBNAIL>thumbnails/03/3191.jpg</THUMBNAIL>\n",
      "</DOC>\n",
      "-------------------------------\n",
      "file 2\n",
      "<DOC>\n",
      "<DOCNO>annotations/03/3193.eng</DOCNO>\n",
      "<TITLE>Anacondas</TITLE>\n",
      "<DESCRIPTION>close-up photo of two anacondas in an aquarium;</DESCRIPTION>\n",
      "<NOTES>Scientific name: Eunectes;</NOTES>\n",
      "<LOCATION>São Paulo, Brazil</LOCATION>\n",
      "<DATE>February 2002</DATE>\n",
      "<IMAGE>images/03/3193.jpg</IMAGE>\n",
      "<THUMBNAIL>thumbnails/03/3193.jpg</THUMBNAIL>\n",
      "</DOC>\n",
      "-------------------------------\n",
      "score:  97.8458485051738\n"
     ]
    }
   ],
   "source": [
    "file_1 = 3191\n",
    "file_2 = 3193\n",
    "\n",
    "out = bow.get_query_score(file_1,file_2)\n",
    "\n",
    "path_1 = f'./Smol_set/annotations_complete_eng/0{str(file_1)[0]}/{file_1}.eng'\n",
    "path_2 = f'./Smol_set/annotations_complete_eng/0{str(file_2)[0]}/{file_2}.eng'\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"file 1\")\n",
    "with open(path_1, 'r', encoding='latin-1') as f:\n",
    "    doc_1 = f.read()\n",
    "    print(doc_1)\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"file 2\")\n",
    "with open(path_2, 'r', encoding='latin-1') as f:\n",
    "    doc_2 = f.read()\n",
    "    print(doc_2)\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"score: \", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "file 1\n",
      "<DOC>\n",
      "<DOCNO>annotations/05/5152.eng</DOCNO>\n",
      "<TITLE>The mountains around Chivay</TITLE>\n",
      "<DESCRIPTION>a mountain landscape with high, steep, bald mountains and a snow covered peak in the background;</DESCRIPTION>\n",
      "<NOTES></NOTES>\n",
      "<LOCATION>Chivay, Peru</LOCATION>\n",
      "<DATE>September 2002</DATE>\n",
      "<IMAGE>images/05/5152.jpg</IMAGE>\n",
      "<THUMBNAIL>thumbnails/05/5152.jpg</THUMBNAIL>\n",
      "</DOC>\n",
      "-------------------------------\n",
      "file 2\n",
      "<DOC>\n",
      "<DOCNO>annotations/05/5155.eng</DOCNO>\n",
      "<TITLE>A condor flying</TITLE>\n",
      "<DESCRIPTION>a flying condor with a bald mountain range in the background;</DESCRIPTION>\n",
      "<NOTES></NOTES>\n",
      "<LOCATION>Cabanaconde, Peru</LOCATION>\n",
      "<DATE>September 2002</DATE>\n",
      "<IMAGE>images/05/5155.jpg</IMAGE>\n",
      "<THUMBNAIL>thumbnails/05/5155.jpg</THUMBNAIL>\n",
      "</DOC>\n",
      "-------------------------------\n",
      "score:  8.419743058659392\n"
     ]
    }
   ],
   "source": [
    "file_1 = 5152\n",
    "file_2 = 5155\n",
    "\n",
    "out = bow.get_query_score(file_1,file_2)\n",
    "\n",
    "path_1 = f'./Smol_set/annotations_complete_eng/0{str(file_1)[0]}/{file_1}.eng'\n",
    "path_2 = f'./Smol_set/annotations_complete_eng/0{str(file_2)[0]}/{file_2}.eng'\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"file 1\")\n",
    "with open(path_1, 'r', encoding='latin-1') as f:\n",
    "    doc_1 = f.read()\n",
    "    print(doc_1)\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"file 2\")\n",
    "with open(path_2, 'r', encoding='latin-1') as f:\n",
    "    doc_2 = f.read()\n",
    "    print(doc_2)\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"score: \", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "file 1\n",
      "<DOC>\n",
      "<DOCNO>annotations/04/4002.eng</DOCNO>\n",
      "<TITLE>At the beach</TITLE>\n",
      "<DESCRIPTION>a sandy beach with a few people sitting in the shade of a palm tree; a wooded slope with houses in the background;</DESCRIPTION>\n",
      "<NOTES></NOTES>\n",
      "<LOCATION>Tobago, Trinidad</LOCATION>\n",
      "<DATE>February 2002</DATE>\n",
      "<IMAGE>images/04/4002.jpg</IMAGE>\n",
      "<THUMBNAIL>thumbnails/04/4002.jpg</THUMBNAIL>\n",
      "</DOC>\n",
      "-------------------------------\n",
      "file 2\n",
      "<DOC>\n",
      "<DOCNO>annotations/04/4005.eng</DOCNO>\n",
      "<TITLE>A wave breaking at the beach</TITLE>\n",
      "<DESCRIPTION>a boy in front of a breaking wave at a sandy beach; two boats at sea in the background;</DESCRIPTION>\n",
      "<NOTES></NOTES>\n",
      "<LOCATION>Tobago, Trinidad</LOCATION>\n",
      "<DATE>February 2002</DATE>\n",
      "<IMAGE>images/04/4005.jpg</IMAGE>\n",
      "<THUMBNAIL>thumbnails/04/4005.jpg</THUMBNAIL>\n",
      "</DOC>\n",
      "-------------------------------\n",
      "score:  28.095881694416732\n"
     ]
    }
   ],
   "source": [
    "file_1 = 4002\n",
    "file_2 = 4005\n",
    "\n",
    "out = bow.get_query_score(file_1,file_2)\n",
    "\n",
    "path_1 = f'./Smol_set/annotations_complete_eng/0{str(file_1)[0]}/{file_1}.eng'\n",
    "path_2 = f'./Smol_set/annotations_complete_eng/0{str(file_2)[0]}/{file_2}.eng'\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"file 1\")\n",
    "with open(path_1, 'r', encoding='latin-1') as f:\n",
    "    doc_1 = f.read()\n",
    "    print(doc_1)\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"file 2\")\n",
    "with open(path_2, 'r', encoding='latin-1') as f:\n",
    "    doc_2 = f.read()\n",
    "    print(doc_2)\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"score: \", out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eef920dd73cd3ef78477e8ab32607aaeccce0de781c75bf88db90c589e446cd3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
